#install datasets module pip install datasets
#install module easyocr pip install easyocr
import requests
import pandas as pd
import torch
import easyocr
import os
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
from PIL import Image
from sklearn.model_selection import train_test_split
from torch.nn.functional import softmax

# Load tokenizer and model
tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)

# OCR Model
reader = easyocr.Reader(['en'])

# Step 1: Fetch real-time news data from NewsAPI
def fetch_news(api_key, query="technology", language="en", page_size=50):
    url = f"https://newsapi.org/v2/everything?q={query}&language={language}&pageSize={page_size}&apiKey={api_key}"
    response = requests.get(url)
    if response.status_code == 200:
        data = response.json()
        return data.get("articles", [])
    return []

# Step 2: Preprocess news data
def preprocess_news(articles):
    news_data = []
    for article in articles:
        title = article.get("title", "")
        content = article.get("content", "")
        if title and content:
            news_data.append({"text": title + " " + content, "label": 0})  # Assume real
    return pd.DataFrame(news_data)

# Step 3: Tokenization
def tokenize_function(examples):
    return tokenizer(examples['text'], padding="max_length", truncation=True)

# Step 4: Train model
def train_model(news_data):
    train_data, test_data = train_test_split(news_data, test_size=0.2, random_state=42)
    train_dataset = Dataset.from_pandas(train_data)
    test_dataset = Dataset.from_pandas(test_data)
    train_dataset = train_dataset.map(tokenize_function, batched=True)
    test_dataset = test_dataset.map(tokenize_function, batched=True)

    training_args = TrainingArguments(
        output_dir='./results', evaluation_strategy="epoch", learning_rate=2e-5, 
        per_device_train_batch_size=16, per_device_eval_batch_size=16, num_train_epochs=3,
        weight_decay=0.01,
    )
    trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=test_dataset)
    trainer.train()
    return trainer

# Step 5: Extract text from images using OCR
def extract_text_from_image(image_path):
    result = reader.readtext(image_path, detail=0)
    return " ".join(result) if result else None

# Step 6: Fake news detection
def detect_fake_news(trainer, text):
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True)
    outputs = trainer.model(**inputs)
    probabilities = softmax(outputs.logits, dim=1)
    prediction = torch.argmax(probabilities, dim=1).item()
    return "REAL" if prediction == 0 else "FAKE", float(probabilities[0][prediction])

# Step 7: Main function
def main():
    api_key = "cf3522f249a947cd8e447587c955c431"
    articles = fetch_news(api_key)
    news_data = preprocess_news(articles)
    trainer = train_model(news_data)
    
    print("Choose an option: \n1. Upload an image\n2. Enter text manually")
    choice = input("Enter 1 or 2: ")
    
    if choice == '1':
        image_path = input("Enter image path: ")
        if os.path.exists(image_path):
            text = extract_text_from_image(image_path)
            if text:
                result, prob = detect_fake_news(trainer, text)
                print(f"The news is {result} with {prob:.2f} probability.")
            else:
                print("No text detected.")
    elif choice == '2':
        text = input("Enter news text: ")
        result, prob = detect_fake_news(trainer, text)
        print(f"The news is {result} with {prob:.2f} probability.")

if __name__ == "__main__":
    main()
